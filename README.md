# markov-chain-netlogo using netlogo
this project created by NetLogo 5.3.1 version 

A Markov chain is a probabilistic model describing a system that changes from state to state, 
and in which the probability of the system being in a certain state at a certain time step depends 
only on the state of the preceding time step. The probability that the j is the next state of the chain, 
given that the current state is state i, is called the transition probability from i to j.
The matrix below gives the transition probabilities. The entry in row i, column j is the transition probability from i to j.
Note that entries in each rows necessarily add up to 1. The graphical representation below shows the states, 
and the possible state transitions. Click “Run” to start the Markov chain.

## change the probabilities to experiment by yourself !

## a great online Markov chain simulator : 
http://markov.yoriz.co.uk/
## a video to understand the markov model :
https://www.youtube.com/watch?v=FBAeduCqJHQ




# screenshots:


![1](https://user-images.githubusercontent.com/45392637/55217782-a4ceba80-5200-11e9-840f-7f4f72625d6f.JPG)


![2](https://user-images.githubusercontent.com/45392637/55217781-a4362400-5200-11e9-9a7d-72af6eaa726d.JPG)

